{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":102672,"databundleVersionId":12375409,"sourceType":"competition"}],"dockerImageVersionId":31040,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nos.listdir('/kaggle/working')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-24T07:00:20.207009Z","iopub.execute_input":"2025-05-24T07:00:20.208095Z","iopub.status.idle":"2025-05-24T07:00:20.213454Z","shell.execute_reply.started":"2025-05-24T07:00:20.208059Z","shell.execute_reply":"2025-05-24T07:00:20.212679Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 1. Setup and Imports¶","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Input\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score, classification_report, confusion_matrix, precision_recall_fscore_support, accuracy_score\nfrom sklearn.utils.class_weight import compute_class_weight\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom PIL import Image\nimport cv2\nfrom transformers import ViTImageProcessor, ViTModel\nimport torch\n\n# Set random seed for reproducibility\ntf.random.set_seed(42)\nnp.random.seed(42)\n\n# Define paths\nbase_dir = '/kaggle/input/soil-classification/soil_classification-2025'\ntrain_dir = os.path.join(base_dir, 'train')\ntest_dir = os.path.join(base_dir, 'test')\ntrain_labels_path = os.path.join(base_dir, 'train_labels.csv')\ntest_ids_path = os.path.join(base_dir, 'test_ids.csv')\nsubmission_path = os.path.join('/kaggle/working', 'submission.csv')\n\n# Define image parameters\nIMG_SIZE = (224, 224)\nBATCH_SIZE = 16\nNUM_CLASSES = 4\nclass_names = ['Alluvial soil', 'Black Soil', 'Clay soil', 'Red soil']\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T07:00:40.398332Z","iopub.execute_input":"2025-05-24T07:00:40.398615Z","iopub.status.idle":"2025-05-24T07:00:40.410342Z","shell.execute_reply.started":"2025-05-24T07:00:40.398596Z","shell.execute_reply":"2025-05-24T07:00:40.409686Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 2. Data Loading and Preprocessing¶","metadata":{}},{"cell_type":"code","source":"# Load training labels\ntrain_labels = pd.read_csv(train_labels_path)\n\n# Verify all images exist\nmissing_files = [img_id for img_id in train_labels['image_id'] if not os.path.exists(os.path.join(train_dir, img_id))]\nif missing_files:\n    train_labels = train_labels[~train_labels['image_id'].isin(missing_files)]\n\n# Map soil types to numeric labels\nlabel_map = {name: idx for idx, name in enumerate(class_names)}\ntrain_labels['label'] = train_labels['soil_type'].map(label_map)\n\n# Load test IDs\ntest_ids = pd.read_csv(test_ids_path)\n\n# Verify test images exist\nmissing_test_files = [img_id for img_id in test_ids['image_id'] if not os.path.exists(os.path.join(test_dir, img_id))]\nif missing_test_files:\n    test_ids = test_ids[~test_ids['image_id'].isin(missing_test_files)]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T06:32:07.166027Z","iopub.execute_input":"2025-05-24T06:32:07.166549Z","iopub.status.idle":"2025-05-24T06:32:07.844731Z","shell.execute_reply.started":"2025-05-24T06:32:07.166522Z","shell.execute_reply":"2025-05-24T06:32:07.843958Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 3. Exploratory Data Analysis (EDA)","metadata":{}},{"cell_type":"code","source":"class_counts = train_labels['soil_type'].value_counts()\nimbalance_ratio = class_counts.max() / class_counts.min()\n\nprint(f\"Class distribution: {dict(class_counts)}\")\nprint(f\"Imbalance ratio: {imbalance_ratio:.2f}\")\n\n# Plot class distribution\nplt.figure(figsize=(8, 6))\nsns.barplot(x=class_counts.values, y=class_counts.index)\nplt.title('Class Distribution of Soil Types')\nplt.xlabel('Number of Images')\nplt.ylabel('Soil Type')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T06:56:22.422004Z","iopub.execute_input":"2025-05-24T06:56:22.422475Z","iopub.status.idle":"2025-05-24T06:56:23.119457Z","shell.execute_reply.started":"2025-05-24T06:56:22.422452Z","shell.execute_reply":"2025-05-24T06:56:23.118672Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 4. Handle Class Imbalance","metadata":{}},{"cell_type":"code","source":"# Compute class weights\nclass_weights = compute_class_weight(\n    class_weight='balanced',\n    classes=np.unique(train_labels['label'].dropna().astype(int)),\n    y=train_labels['label']\n)\nclass_weights = dict(enumerate(class_weights))\n\n# Split training data into train and validation sets\ntrain_df, val_df = train_test_split(train_labels, test_size=0.2, stratify=train_labels['soil_type'], random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T06:32:14.970229Z","iopub.execute_input":"2025-05-24T06:32:14.970748Z","iopub.status.idle":"2025-05-24T06:32:14.981468Z","shell.execute_reply.started":"2025-05-24T06:32:14.970725Z","shell.execute_reply":"2025-05-24T06:32:14.980707Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 5. ViT Feature Extraction","metadata":{}},{"cell_type":"code","source":"# Initialize ViT processor and model\nimage_processor = ViTImageProcessor.from_pretrained(\"google/vit-base-patch16-224-in21k\", trust_remote_code=True)\nimage_processor.do_rescale = False  # Images are already normalized\nvit_model = ViTModel.from_pretrained(\"google/vit-base-patch16-224-in21k\", trust_remote_code=True).to(device)\n\n# Function to load and preprocess image\ndef load_image(image_path):\n    img = cv2.imread(image_path)\n    if img is None:\n        return None\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = cv2.resize(img, IMG_SIZE)\n    return img / 255.0\n\n# Function to extract ViT features\ndef get_vit_features(image_paths):\n    images = []\n    valid_paths = []\n    for path in image_paths:\n        img = load_image(path)\n        if img is not None:\n            images.append(img)\n            valid_paths.append(path)\n    if not images:\n        return None, []\n    inputs = image_processor(images=images, return_tensors=\"pt\").to(device)\n    with torch.no_grad():\n        outputs = vit_model(**inputs).last_hidden_state[:, 0, :].cpu().numpy()\n    return outputs, valid_paths\n\n# Extract features for training and validation sets\ntrain_image_paths = [os.path.join(train_dir, img_id) for img_id in train_df['image_id']]\nval_image_paths = [os.path.join(train_dir, img_id) for img_id in val_df['image_id']]\n\n# Process in batches to manage memory\ndef batch_process_features(image_paths, batch_size=32):\n    features = []\n    valid_indices = []\n    for i in range(0, len(image_paths), batch_size):\n        batch_paths = image_paths[i:i + batch_size]\n        batch_features, valid_paths = get_vit_features(batch_paths)\n        if batch_features is not None:\n            features.append(batch_features)\n            valid_indices.extend([image_paths.index(p) for p in valid_paths])\n    if not features:\n        raise ValueError(\"No valid features extracted.\")\n    return np.concatenate(features, axis=0), valid_indices\n\ntrain_features, train_valid_indices = batch_process_features(train_image_paths)\nval_features, val_valid_indices = batch_process_features(val_image_paths)\n\n# Filter labels for valid images\ntrain_labels_filtered = train_df.iloc[train_valid_indices]['label'].values\nval_labels_filtered = val_df.iloc[val_valid_indices]['label'].values\n\n# Convert labels to one-hot encoding\ntrain_labels_onehot = tf.keras.utils.to_categorical(train_labels_filtered, NUM_CLASSES)\nval_labels_onehot = tf.keras.utils.to_categorical(val_labels_filtered, NUM_CLASSES)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T06:34:24.476572Z","iopub.execute_input":"2025-05-24T06:34:24.477289Z","iopub.status.idle":"2025-05-24T06:34:50.563490Z","shell.execute_reply.started":"2025-05-24T06:34:24.477262Z","shell.execute_reply":"2025-05-24T06:34:50.562663Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 6. Model Definition and Training","metadata":{}},{"cell_type":"code","source":"# Define dense classifier\nmodel = Sequential([\n    Input(shape=(768,)),\n    Dense(256, activation='relu'),\n    Dropout(0.5),\n    Dense(128, activation='relu'),\n    Dropout(0.5),\n    Dense(NUM_CLASSES, activation='softmax')\n])\n\n# Compile the model\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\n# Train the model\nhistory = model.fit(\n    train_features,\n    train_labels_onehot,\n    epochs=100,\n    batch_size=BATCH_SIZE,\n    validation_data=(val_features, val_labels_onehot),\n    class_weight=class_weights,\n    callbacks=[\n        tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n        tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=3)\n    ],\n    verbose=0\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T06:47:49.391588Z","iopub.execute_input":"2025-05-24T06:47:49.391920Z","iopub.status.idle":"2025-05-24T06:48:03.619163Z","shell.execute_reply.started":"2025-05-24T06:47:49.391900Z","shell.execute_reply":"2025-05-24T06:48:03.618603Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 7. Evaluation","metadata":{}},{"cell_type":"code","source":"# Plot training history\nplt.figure(figsize=(12, 4))\nplt.subplot(1, 2, 1)\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.title('Loss Over Epochs')\nplt.legend()\nplt.subplot(1, 2, 2)\nplt.plot(history.history['accuracy'], label='Training Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.title('Accuracy Over Epochs')\nplt.legend()\nplt.show()\n\n# Calculate final metrics and plot confusion matrix\nval_predictions = model.predict(val_features, verbose=0)\nval_pred_labels = np.argmax(val_predictions, axis=1)\nval_true_labels = np.argmax(val_labels_onehot, axis=1)\nf1_scores = f1_score(val_true_labels, val_pred_labels, average=None)\nmin_f1 = np.min(f1_scores)\n\n# Plot confusion matrix\ncm = confusion_matrix(val_true_labels, val_pred_labels)\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n            xticklabels=class_names, yticklabels=class_names)\nplt.title('Confusion Matrix')\nplt.ylabel('True Label')\nplt.xlabel('Predicted Label')\nplt.tight_layout()\nplt.show()\n\nprint(f\"Validation F1-scores: {dict(zip(class_names, f1_scores))}\")\nprint(f\"Minimum F1-score: {min_f1:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T06:57:42.273408Z","iopub.execute_input":"2025-05-24T06:57:42.274234Z","iopub.status.idle":"2025-05-24T06:57:44.964933Z","shell.execute_reply.started":"2025-05-24T06:57:42.274207Z","shell.execute_reply":"2025-05-24T06:57:44.964113Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 8. Test Set Predictions and Submission","metadata":{}},{"cell_type":"code","source":"# Extract features for test set\ntest_image_paths = [os.path.join(test_dir, img_id) for img_id in test_ids['image_id']]\ntest_features, test_valid_indices = batch_process_features(test_image_paths)\n\n# Filter test IDs for valid images\ntest_ids_filtered = test_ids.iloc[test_valid_indices]\n\n# Generate predictions\ntest_predictions = model.predict(test_features, verbose=0)\ntest_pred_labels = np.argmax(test_predictions, axis=1)\ntest_pred_soil_types = [class_names[label] for label in test_pred_labels]\n\n# Create submission DataFrame\nsubmission_df = pd.DataFrame({\n    'image_id': test_ids_filtered['image_id'],\n    'soil_type': test_pred_soil_types\n})\n\n# Save submission\nsubmission_df.to_csv(submission_path, index=False)\nprint(f\"Submission saved: {submission_df.shape[0]} predictions\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T07:00:46.404453Z","iopub.execute_input":"2025-05-24T07:00:46.404958Z","iopub.status.idle":"2025-05-24T07:00:55.469283Z","shell.execute_reply.started":"2025-05-24T07:00:46.404933Z","shell.execute_reply":"2025-05-24T07:00:55.468487Z"}},"outputs":[],"execution_count":null}]}